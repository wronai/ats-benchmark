{
  "results": [
    {
      "tool": "code2logic",
      "target_project": "/project",
      "tokens_in": 223224,
      "tokens_out": 2265,
      "duration_analysis_sec": 10.469593524932861,
      "duration_llm_sec": 146.21348071098328,
      "duration_total_sec": 156.68744683265686,
      "context_chars": 678039,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.7570201199420179,
      "llm_response": " Based on the AST and function logic provided, here is a comprehensive code review identifying critical issues across the codebase:\n\n## 1. Security Concerns (Critical)\n\n### **SQL Injection Vulnerability**\n- **Function**: `unsafe_sql_lookup` (appears in all app/*.py files: config.py, db.py, orders.py, etc.)\n- **Issue**: The function accepts `user_input:str` and calls `conn.execute` directly without parameterization or sanitization.\n- **Risk**: Direct SQL injection allowing arbitrary query execution.\n- **Fix**: Use parameterized queries: `conn.execute(\"SELECT * FROM ? WHERE id = ?\", (table, user_input))`\n\n### **Arbitrary Code Execution**\n- **Function**: `insecure_eval` (lines 26-28, all modules)\n- **Issue**: Uses `eval(expression)` on unsanitized string input.\n- **Risk**: Remote code execution vulnerability.\n- **Fix**: Replace with `ast.literal_eval` for safe evaluation or use a restricted parser.\n\n### **Mutable Default Argument Security Risk**\n- **Functions**: `accumulate`, all `generated_rule_*` functions (0-219), `async_fetch_with_blocking_sleep`\n- **Issue**: Uses mutable defaults like `acc:list[int]=[]` and `cache:dict[str,Any]={}`.\n- **Risk**: State leakage between calls; cache poisoning; data exposure between requests.\n- **Fix**: Use `None` as default and initialize inside function.\n\n## 2. Logic Errors & Bugs\n\n### **Division by Zero**\n- **Function**: `broken_average` (lines 51-53, all modules)\n- **Issue**: Returns `sum(values) / len(values)` without checking for empty list.\n- **Fix**: Add guard: `if not values: return 0.0` or raise `ValueError`.\n\n### **Async/Blocking Mismatch**\n- **Function**: `async_fetch_with_blocking_sleep` (lines 37-41)\n- **Issue**: Async function calls `time.sleep` (blocking) alongside `asyncio.sleep`.\n- **Impact**: Blocks the event loop, defeating the purpose of async.\n- **Fix**: Remove `time.sleep` or use `await asyncio.sleep()` exclusively.\n\n### **Race Condition in Threading**\n- **Function**: `non_atomic_increment` (lines 72-86)\n- **Issu...",
      "llm_quality_keywords": 21,
      "error": null,
      "metadata": {
        "parser": "tree-sitter",
        "format": "compact+function_logic"
      }
    },
    {
      "tool": "nfo",
      "target_project": "/project",
      "tokens_in": 41950,
      "tokens_out": 2545,
      "duration_analysis_sec": 0.1864767074584961,
      "duration_llm_sec": 144.18799233436584,
      "duration_total_sec": 144.3789005279541,
      "context_chars": 160307,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.9425528979417778,
      "llm_response": " Based on the NFO representation, this codebase exhibits severe architectural anti-patterns, security vulnerabilities, and logic errors. Here's the detailed analysis:\n\n## 1. Critical Security Concerns\n\n### SQL Injection (Critical)\n- **Function**: `unsafe_sql_lookup()` in **all modules** (`app/db.py`, `app/auth.py`, `app/api.py`, etc.)\n- **Issue**: Function name indicates raw SQL construction without parameterization\n- **Recommendation**: Replace with parameterized queries using SQLAlchemy or `sqlite3` parameterized statements. Never concatenate user input into SQL.\n\n### Remote Code Execution (Critical)\n- **Function**: `insecure_eval()` in **all modules**\n- **Issue**: Likely uses Python's `eval()` on untrusted input\n- **Recommendation**: Replace with `ast.literal_eval()` for safe parsing, or use JSON schema validation. If dynamic code execution is required, implement a sandboxed environment with restricted builtins.\n\n### Unsafe Deserialization\n- **Function**: `parse_payload()` in **all modules**\n- **Issue**: Returns `dict[str, Any]` with no validation; likely parses external input without schema validation\n- **Recommendation**: Implement Pydantic models or marshmallow schemas to validate all incoming payloads before processing.\n\n## 2. Bugs & Logic Errors\n\n### Division by Zero / Incorrect Average\n- **Function**: `broken_average()` → `float` (present in all modules)\n- **Issue**: Name suggests incorrect calculation; likely fails on empty lists or uses integer division\n- **Evidence**: Test `test_broken_average_single_value()` exists specifically for this\n- **Recommendation**: Add empty list guard: `return sum(items) / len(items) if items else 0.0`\n\n### State Leakage Between Calls\n- **Function**: `accumulate()` → `list[int]`\n- **Issue**: Test `test_accumulate_should_not_leak_state()` indicates mutable default arguments or static state\n- **Recommendation**: Initialize accumulators inside function scope, not as default parameters:\n  ```python\n  def accumulate(items: list[in...",
      "llm_quality_keywords": 22,
      "error": null,
      "metadata": {
        "mode": "data_flow+runtime",
        "has_runtime_logs": false
      }
    },
    {
      "tool": "baseline-raw",
      "target_project": "/project",
      "tokens_in": 54197,
      "tokens_out": 1997,
      "duration_analysis_sec": 0.0010728836059570312,
      "duration_llm_sec": 50.48562240600586,
      "duration_total_sec": 50.49013304710388,
      "context_chars": 232610,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.0,
      "llm_response": " Code Review: `app/analytics.py` & `app/__init__.py`\n\n## 1. Critical Security Vulnerabilities\n\n**`unsafe_sql_lookup(conn, table, user_input)`** (Line ~15)\n- **SQL Injection**: Both `table` and `user_input` are interpolated directly into the query string without parameterization. Attackers can inject SQL via either parameter (e.g., `user_input=\"'; DROP TABLE users; --\"`).\n- **Fix**: Use parameterized queries: `conn.execute(\"SELECT * FROM ? WHERE name = ?\", (table, user_input))`.\n\n**`insecure_eval(expression)`** (Line ~19)\n- **Arbitrary Code Execution**: `eval()` executes arbitrary Python code. This is a critical RCE vulnerability.\n- **Fix**: Replace with `ast.literal_eval()` for literals, or implement a safe math parser (e.g., `simpleeval`).\n\n**Hardcoded Secrets** (All `generated_rule_*` functions, Lines ~50+)\n- 200+ functions contain hardcoded secrets (`secret = \"hardcoded-secret-N\"`). These are rotated through a small set of 17 values (0-16) but exposed in source code.\n- **Fix**: Use environment variables or a secrets manager (e.g., `os.environ.get(\"SECRET\")`).\n\n## 2. Logic Errors & Data Flow Issues\n\n**`broken_average(values)`** (Line ~35)\n- **Off-by-one Error**: Divides by `len(values) - 1` instead of `len(values)`. Crashes with `ZeroDivisionError` when passed a single element list.\n- **Fix**: Change to `len(values)` and handle empty list edge case.\n\n**`accumulate(values, acc=[])`** (Line ~31)\n- **Mutable Default Argument**: The default `acc=[]` is evaluated once at import time, causing state leakage between calls.\n- **Fix**: Use `acc=None` and initialize inside function.\n\n**`parse_payload(raw)`** (Line ~23)\n- **Data Corruption**: Blindly replaces single quotes with double quotes before JSON parsing, corrupting valid JSON strings containing apostrophes (e.g., `\"name\": \"O'Brien\"` becomes invalid JSON).\n- **Fix**: Remove the replacement; handle JSON parsing properly with error handling.\n\n**`generated_rule_*` functions** (Lines ~50 to end)\n- **Division by Zero**: `ra...",
      "llm_quality_keywords": 18,
      "error": null,
      "metadata": {
        "mode": "raw_source"
      }
    },
    {
      "tool": "callgraph",
      "target_project": "/project",
      "tokens_in": 1470,
      "tokens_out": 2112,
      "duration_analysis_sec": 2.0507774353027344,
      "duration_llm_sec": 52.56457185745239,
      "duration_total_sec": 54.61926245689392,
      "context_chars": 4841,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.9982651947758747,
      "llm_response": "Based on this callgraph analysis, I've identified several critical issues, primarily centered around **massive code duplication** and **unsafe data handling patterns**.\n\n## 1. Critical Refactoring Opportunity: Generated Code Bloat\n\n**Issue**: The `app.analytics` module contains 200+ functions (`generated_rule_0` through `generated_rule_115+`) with **identical call signatures and structures**.\n\n**Evidence**: Every function follows the exact pattern:\n```\nget → int → int → get → get → get → str\n```\n\n**Problems**:\n- **Severe DRY violation**: Logic duplicated 200 times\n- **Memory bloat**: 200+ function objects vs. 1 parameterized function\n- **Maintenance nightmare**: Bug fixes require editing 200 locations\n- **Debuggability**: Numeric function names provide zero semantic context\n\n**Recommendation**:\nReplace with a data-driven rule engine:\n```python\n# Instead of 200 functions\nRULES = [\n    {'id': 0, 'int_fields': ['field1', 'field2'], 'str_fields': ['field3'], ...},\n    {'id': 1, 'int_fields': [...], ...},\n]\n\ndef execute_rule(rule_id, data):\n    rule = RULES[rule_id]\n    # Single implementation with validation\n```\n\n## 2. Data Flow Issues: Unsafe Type Conversions\n\n**Issue**: Unvalidated `int()` conversions in every `generated_rule_X` function.\n\n**Evidence**: Each rule calls `int` twice without preceding validation calls.\n\n**Potential Bugs**:\n- `int(None)` → `TypeError`\n- `int(\"\")` or `int(\"abc\")` → `ValueError`\n- No validation that `get` returned a value before conversion\n\n**Recommendation**:\n```python\n# Add validation wrapper\ndef safe_int_convert(value, rule_id, field_name):\n    if value is None:\n        raise ValueError(f\"Rule {rule_id}: Missing required field {field_name}\")\n    try:\n        return int(value)\n    except (ValueError, TypeError):\n        # Handle or log appropriately\n        raise\n```\n\n## 3. Security Concerns: Dangerous Function Exposure\n\n**Critical**: `__root__` namespace contains high-risk functions accessible to generated code:\n\n- **`eval`**: If any `ge...",
      "llm_quality_keywords": 18,
      "error": null,
      "metadata": {
        "nodes": 2834,
        "edges": 18712,
        "entry_points": 0
      }
    },
    {
      "tool": "treesitter",
      "target_project": "/project",
      "tokens_in": 922,
      "tokens_out": 1972,
      "duration_analysis_sec": 2.2707090377807617,
      "duration_llm_sec": 18.012399435043335,
      "duration_total_sec": 20.28741216659546,
      "context_chars": 3214,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.99884824127446,
      "llm_response": " Based on the AST representation provided, here is a critical analysis of the codebase:\n\n## 1. Critical Security Vulnerabilities\n\n### SQL Injection Risk (Severity: Critical)\n**Location**: `unsafe_sql_lookup` in `app/analytics.py`, `app/api.py`, `app/auth.py`, `app/config.py`, `app/db.py`, `app/etl.py`, `app/inventory.py`, `app/logging_pipeline.py`, `app/orders.py`\n\n**Issue**: The function name `unsafe_sql_lookup` is an explicit indicator of dangerous raw SQL execution. The AST shows this function accepts a `conn` parameter (database connection) but reveals no parameter validation or query parameterization nodes.\n\n**Recommendation**: \n- Immediately audit all 9 instances for string concatenation SQL queries\n- Replace with parameterized queries: `cursor.execute(\"SELECT * FROM table WHERE id = ?\", (user_id,))`\n- Consider using SQLAlchemy or similar ORM to eliminate injection vectors\n\n## 2. Extreme Code Duplication (DRY Violations)\n\n**Location**: All modules except `app/__init__.py`\n\n**Issue**: Identical function signatures (`unsafe_sql_lookup` with `conn` parameter) appear in 9 separate files with identical AST node counts (76,008 nodes, depth 13). This suggests:\n- Copy-paste programming across the entire data layer\n- No centralized database abstraction\n- Potential maintenance nightmare when fixing the SQL injection bug\n\n**Recommendation**:\n- **Consolidate**: Move all database utilities exclusively to `app/db.py`\n- **Delete** duplicate functions from `app/auth.py`, `app/api.py`, `app/analytics.py`, etc.\n- Create a `DatabaseManager` class or repository pattern to decouple business logic from data access\n\n## 3. Data Flow & Connection Management Issues\n\n**Location**: Parameters in `unsafe_sql_lookup` across all files\n\n**Issue**: \n- **Missing Type Safety**: The AST shows `(type)` is empty for the `conn` parameter - no type hints (e.g., `sqlite3.Connection`, `psycopg2.extensions.connection`)\n- **Connection Leak Risk**: No visible context managers (`with` statements) in the t...",
      "llm_quality_keywords": 18,
      "error": null,
      "metadata": {
        "parser": "tree-sitter",
        "language": "python",
        "has_native_parser": true
      }
    },
    {
      "tool": "ast-grep",
      "target_project": "/project",
      "tokens_in": 1283,
      "tokens_out": 2743,
      "duration_analysis_sec": 2.572171688079834,
      "duration_llm_sec": 162.8187358379364,
      "duration_total_sec": 165.396803855896,
      "context_chars": 4025,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.9985576139171444,
      "llm_response": " Based on the ast-grep structural analysis, here is a comprehensive code review:\n\n## 1. Critical Bugs & Logic Errors\n\n### **Race Condition in `worker` Function** (Critical)\n**Location:** `/project/app/api.py:75`, `/project/app/utils.py:75`, `/project/app/db.py:75`, and 3 other files\n```python\ndef worker():  # PARAMS= is empty but body uses undefined `n`\n    global GLOBAL_COUNTER\n    for _ in range(n):  # BUG: `n` is undefined in the parameter list\n        GLOBAL_COUNTER += 1  # Race condition: non-atomic operation across threads\n```\n- **Issue:** The `worker` function references `n` which is not in the function signature, and modifies global state from multiple threads without synchronization.\n- **Fix:** Add `n` parameter and use `threading.Lock()`:\n```python\ncounter_lock = threading.Lock()\n\ndef worker(n: int):\n    global GLOBAL_COUNTER\n    for _ in range(n):\n        with counter_lock:\n            GLOBAL_COUNTER += 1\n```\n\n### **Silent Error Swallowing in `flaky_retry`** (High)\n**Location:** `/project/app/api.py:55`, `/project/app/utils.py:55`, `/project/app/db.py:55`, `/project/app/inventory.py:55`, `/project/app/recommendations.py:55`, `/project/app/etl.py:55`\n- **Issue:** The comment indicates this decorator catches all exceptions and returns `None`, masking failures and making debugging impossible.\n- **Fix:** Implement proper exception logging and selective retry logic:\n```python\ndef flaky_retry(fn):\n    @wraps(fn)\n    def wrapper(*args, **kwargs):\n        try:\n            return fn(*args, **kwargs)\n        except RetryableException as e:  # Be specific\n            logger.warning(f\"Retryable error in {fn.__name__}: {e}\")\n            return None\n        except Exception as e:\n            logger.error(f\"Critical error in {fn.__name__}: {e}\")\n            raise  # Don't swallow unexpected errors\n    return wrapper\n```\n\n### **Missing Constructor Parameter**\n**Location:** `/project/app/api.py:89`, `/project/app/utils.py:89`, etc. (6 files)\n```python\ndef __init__(self): ...",
      "llm_quality_keywords": 18,
      "error": null,
      "metadata": {
        "patterns_used": 9,
        "method": "ast-grep"
      }
    },
    {
      "tool": "radon",
      "target_project": "/project",
      "tokens_in": 458,
      "tokens_out": 2553,
      "duration_analysis_sec": 8.618851661682129,
      "duration_llm_sec": 82.80193328857422,
      "duration_total_sec": 91.42547178268433,
      "context_chars": 1008,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.9996387763549023,
      "llm_response": "Based on this Radon analysis, I see several **critical architectural red flags** that suggest systemic issues beyond just \"complex code.\" The metrics reveal patterns consistent with monolithic god-classes, potential circular dependencies, and high-risk security anti-patterns.\n\n## 1. Potential Bugs & Logic Errors\n\n**The \"Zero Maintainability\" Anomaly**\n- **Files**: `config.py`, `auth.py`, `payments.py`, `analytics.py`, etc. (MI=0.0)\n- **Issue**: A Maintainability Index of 0.0 indicates these files are mathematically unmaintainable. The MI formula (171 - 5.2ln(Halstead Volume) - 0.23(CC) - 16.2ln(LOC)) yielding zero suggests either:\n  - Extreme cyclomatic complexity (likely nested conditionals 10+ levels deep)\n  - Massive Halstead volume (excessive operators/operands)\n  - **Most likely**: The identical 4,684 SLOC count across different domains suggests **generated code or copy-paste templates** that may contain orphaned logic or unreachable code blocks\n\n**The Identical File Size Pattern**\n- **Observation**: 5 different functional domains (config, logging, analytics, auth, payments) all have exactly **4,684 SLOC**\n- **Bug Risk**: This statistical impossibility indicates:\n  - Boilerplate duplication across modules leading to divergent logic bugs (fixing auth but not payments)\n  - Potential circular import issues in `config.py` (common in large config files)\n  - Copy-paste errors where domain-specific validation was left as generic template code\n\n## 2. Data Flow Issues\n\n**Configuration Hell (`config.py`)**\n- **Risk**: 4,684 lines of configuration suggests **hardcoded environment-specific values** (API keys, DB URLs) rather than environment variable injection\n- **Data Flow**: Likely imported by all other modules, creating a **bottleneck** where changes trigger cascading re-imports\n- **Missing Validation**: Config files this large rarely have centralized schema validation; expect `KeyError` or `NoneType` exceptions at runtime\n\n**Logging Pipeline Coupling (`logging_pipeline...",
      "llm_quality_keywords": 22,
      "error": null,
      "metadata": {
        "metrics": [
          "cyclomatic_complexity",
          "maintainability_index",
          "raw_metrics",
          "halstead"
        ]
      }
    },
    {
      "tool": "bandit",
      "target_project": "/project",
      "tokens_in": 570,
      "tokens_out": 2028,
      "duration_analysis_sec": 16.675747871398926,
      "duration_llm_sec": 54.772310733795166,
      "duration_total_sec": 71.45241904258728,
      "context_chars": 1867,
      "raw_code_chars": 2790515,
      "compression_ratio": 0.9993309478716295,
      "llm_response": "Based on this Bandit security analysis, I've identified critical systemic issues beyond the individual vulnerabilities. The identical line numbers across multiple files indicate **copy-paste programming** and **architectural decay**.\n\n## 1. Critical Security Concerns\n\n### SQL Injection Epidemic (Line 22)\n**Files affected:** `auth.py`, `api.py`, `analytics.py`, `db.py`, `config.py`\n- **Critical Risk:** `auth.py` contains SQL injection vectors in the authentication layer, potentially allowing credential bypass or privilege escalation\n- **Configuration Risk:** `config.py` executing SQL suggests database access in configuration loading, violating separation of concerns\n- **Pattern:** Identical line numbers indicate a copy-pasted database utility function using string formatting (e.g., `f\"SELECT * FROM {table}\"` or `.format()` interpolation)\n\n**Immediate Action:**\n```python\n# Replace in all files (line 22)\n# VULNERABLE:\ncursor.execute(f\"SELECT * FROM users WHERE id = {user_id}\")\n\n# SECURE:\ncursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n```\n\n### Arbitrary Code Execution (Line 28)\n**High confidence blacklist hits** across 8+ files indicate widespread use of `eval()`, `exec()`, or `pickle.loads()`\n- **Data Flow Issue:** Unsanitized user input reaching execution functions\n- **Refactoring:** Replace with `ast.literal_eval()` for safe literal evaluation or JSON parsing for data serialization\n\n## 2. Architecture & Data Flow Issues\n\n### Missing Data Access Layer (DAL)\n**Problem:** SQL construction appearing in `api.py`, `auth.py`, and `analytics.py` violates layered architecture\n- **Data Flow Issue:** Database logic leaks into presentation/API layer\n- **Recommendation:** Centralize all SQL in `db.py` behind parameterized stored procedures or ORM models\n\n### Input Validation Gap\nThe prevalence of injection vulnerabilities suggests:\n- No centralized input sanitization middleware\n- Missing validation schemas (Pydantic/Cerberus) before database operations\n- Trust bo...",
      "llm_quality_keywords": 18,
      "error": null,
      "metadata": {
        "focus": "security_vulnerabilities",
        "categories": [
          "injection",
          "xss",
          "crypto",
          "deserialization",
          "secrets"
        ]
      }
    }
  ],
  "tools_count": 8,
  "errors_count": 0
}